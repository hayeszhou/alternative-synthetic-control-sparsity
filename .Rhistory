abline(v=mcv,
lty=2,col="firebrick")
beta0
mcv
fit <-  lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=LassoPen(c=.55,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
fit
fit <-  lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=LassoPen(c=.2,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
fit
### Calibration cross-validation
### 22 fevrier 2016
### J L'Hour
### Set working directory
setwd("R:/Simulations/R_Code")
rm(list=ls())
set.seed(30031987)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
library("lbfgs")
### Load user-defined functions
source("functions/DataSim.R")
source("functions/gamma.R")
source("functions/gammagrad.R")
### Data simulation
data <- DataSim(n=2000,p=100,Ry=.8,Rd=.2)
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- data$y
d <- data$d
n <- nrow(X)
p <- ncol(X)
# Overall penalty level
LassoPen <- function(c=1.1,n,p){
g <- .1/log(max(p,n))
lambda <- c*qnorm(1-.5*g/p)/sqrt(n)
return(lambda)
}
# 10-fold cross-validation
c_set <- seq(0,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
print(Sys.time()-t_start)
# Best value of C by cross-validation
mcv <- c_set[which(apply(cv_error,2,mean)== min(apply(cv_error,2,mean)))]
# Plot the result
plot(c_set,apply(cv_error,2,mean),
col="steelblue", pch=20,
ylim=c(.5,.7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
# Best value of C by cross-validation
mcv <- c_set[which(apply(cv_error,2,sum)== min(apply(cv_error,2,mean)))]
# Plot the result
plot(c_set,apply(cv_error,2,sum),
col="steelblue", pch=20,
ylim=c(.5,.7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
plot(c_set,apply(cv_error,2,sum),
col="steelblue", pch=20,
ylim=c(5,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
mcv
# Best value of C by cross-validation
mcv <- c_set[which(apply(cv_error,2,sum)== min(apply(cv_error,2,sum)))]
# Plot the result
plot(c_set,apply(cv_error,2,sum),
col="steelblue", pch=20,
ylim=c(5,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
cv_error
load("datasets/LalondeData.R")
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- (data$y - mean(data$y))/sd(data$y)
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(0,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
beta0
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
cv_error
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
load("datasets/LalondeData_Unscaled.R")
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- (data$y - mean(data$y))/sd(data$y)
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
load("datasets/LalondeData_Unscaled.R")
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- (data$y - mean(data$y))/sd(data$y)
d <- data$d
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- (data$y - mean(data$y))/sd(data$y)
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
load("datasets/LalondeData_Unscaled.R")
X <- data$X
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- c(log(sum(d)/(sum(1-d))),rep(0,p-1))
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
cv_error
lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=0)
fit
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=0,
orthantwise_start=1,invisible=1)
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=0,
orthantwise_start=1,invisible=0)
LassoPen(c=2,n=nrow(X_s2),p=ncol(X_s2))
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=.16,
orthantwise_start=1,invisible=0)
beta0
beta0 <- beta0$par
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
beta0 <- fit$par
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
cv_error
mcv <- c_set[which(apply(cv_error,2,mean,na.rm=T)== min(apply(cv_error,2,mean,na.rm=T)))]
mcv
apply(cv_error,2,mean,na.rm=T)
mcv <- c_set[which(apply(cv_error,2,mean,na.rm=T)== min(apply(cv_error,2,mean,na.rm=T),na.rm=T))]
# Plot the result
plot(c_set,apply(cv_error,2,sum,na.rm=T),
col="steelblue", pch=20,
ylim=c(5,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
# Plot the result
plot(c_set,apply(cv_error,2,mean,na.rm=T),
col="steelblue", pch=20,
ylim=c(5,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
# Plot the result
plot(c_set,apply(cv_error,2,mean,na.rm=T),
col="steelblue", pch=20,
ylim=c(0,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
# Plot the result
plot(c_set,apply(cv_error,2,mean,na.rm=T),
col="steelblue", pch=20,
ylim=c(0,3),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
v=2
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
sum(d_s2)
beta0
load("datasets/LalondeData_Unscaled.R")
X <- data$X[1:10,]
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=.16,
orthantwise_start=1,invisible=0)
p
n <- nrow(X)
p <- ncol(X)
p
X <- data$X[1:10,]
d <- data$d
n <- nrow(X)
p <- ncol(X)
p
load("datasets/LalondeData_Unscaled.R")
X <- data$X[,1:10]
d <- data$d
n <- nrow(X)
p <- ncol(X)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
# 10-fold cross-validation
c_set <- seq(.5,5,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=.16,
orthantwise_start=1,invisible=0)
beta0 <- beta0$par
beta0
# 10-fold cross-validation
c_set <- seq(0,4,by=0.05)
fold <- sample(rep(1:10,each=n/10))
beta0 <- rep(0,p)
cv_error <- matrix(NA,nrow=10,ncol=length(c_set))
j <- 0
t_start <- Sys.time()
beta0 <- lbfgs(gamma, gammagrad, beta0, d=d, X=X,
orthantwise_c=.16,
orthantwise_start=1,invisible=0)
beta0 <- beta0$par
beta0
for(c in c_set){
j <- j+1
print(paste("penalty level:",c))
for(v in 1:10){
# Compute model
X_s2 <- X[which(fold!=v),]
d_s2 <- d[which(fold!=v)]
fit <-  lbfgs(gamma, gammagrad, beta0, d=d_s2, X=X_s2,
orthantwise_c=LassoPen(c=c,n=nrow(X_s2),p=ncol(X_s2)),
orthantwise_start=1,invisible=1)
beta0 <- fit$par
# Estimate on the left-out sample
X_s1 <- X[which(fold==v),]
d_s1 <- d[which(fold==v)]
cv_error[v,j] <- gamma(fit$par,d_s1,X_s1)
}
}
print(Sys.time()-t_start)
# Best value of C by cross-validation
mcv <- c_set[which(apply(cv_error,2,sum)== min(apply(cv_error,2,sum)))]
# Plot the result
plot(c_set,apply(cv_error,2,sum),
col="steelblue", pch=20,
ylim=c(5,7),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
plot(c_set,apply(cv_error,2,sum),
col="steelblue", pch=20,
ylim=c(0,3),
xlab="Penalty value",
ylab="Cross-validation error")
abline(v=mcv,
lty=2,col="firebrick")
### Set working directory
setwd("R:/Simulations/R_Code")
rm(list=ls())
set.seed(30031987)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/DataSim.R")
source("functions/LassoFISTA.R")
### Data simulation
data <- DataSim(n=200,p=100,Ry=.8,Rd=.2)
X <- scale(data$X)
X[,1] <- rep(1,nrow(X))
y <- data$y
d <- data$d
n <- nrow(X)
p <- ncol(X)
# Overall penalty level
LassoPen <- function(c=1.1,n,p){
g <- .1/log(max(p,n))
lambda <- c*qnorm(1-.5*g/p)/sqrt(n)
return(lambda)
}
# Loss function
LeastSq <- function(mu,y,X){
X <- as.matrix(X)
return(mean((y - X%*%mu)^2))
}
### Comparison with LARS
fit <- LassoFISTA(betaInit=rep(0,p),y,X,
nopen=c(1),lambda=LassoPen(c=1.1,n=nrow(X),p=ncol(X)),
tol=1e-6,maxIter=1e4,trace=T)
fit
library("lars")
? lars
lars_fit <- lars(X,y, type="lasso", normalize=F,intercept=T,trace=T)
lars
? drop
one
coef(lars_fit, s=LassoPen(c=1.1,n=nrow(X),p=ncol(X)), type="lambda")
coef(lars_fit, s=LassoPen(c=1.1,n=nrow(X),p=ncol(X)), mode="lambda")
coef(lars_fit, s=n*LassoPen(c=1.1,n=nrow(X),p=ncol(X)), mode="lambda")
fit$beta
coef(lars_fit, s=n*LassoPen(c=1.1,n=nrow(X),p=ncol(X))/2, mode="lambda")
lars_fit <- lars(X,y, type="lasso", normalize=F,intercept=F,trace=T)
coef(lars_fit, s=n*LassoPen(c=1.1,n=nrow(X),p=ncol(X))/2, mode="lambda")
fit$beta
sum(fit$beta)
sum(abs(fit$beta))
sum(abs(betalars))
betalars <- coef(lars_fit, s=n*LassoPen(c=1.1,n=nrow(X),p=ncol(X))/2, mode="lambda")
sum(abs(fit$beta))
sum(abs(betalars))
LeastSq(fit$beta,y,X)
LeastSq(betalars,y,X)
fit <- LassoFISTA(betaInit=betalars,y,X,
nopen=c(1),lambda=LassoPen(c=1.1,n=nrow(X),p=ncol(X)),
tol=1e-6,maxIter=1e4,trace=T)
fit
### Comparison with LARS
fit <- LassoFISTA(betaInit=rep(0,p),y,X,
nopen=c(1),lambda=LassoPen(c=1.1,n=nrow(X),p=ncol(X)),
tol=1e-6,maxIter=1e4,trace=T)
library("lars")
lars_fit <- lars(X,y, type="lasso", normalize=F,intercept=F,trace=T)
betalars <- coef(lars_fit, s=n*LassoPen(c=1.1,n=nrow(X),p=ncol(X))/2, mode="lambda")
LeastSq(fit$beta,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(fit$beta))
LeastSq(betalars,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(betalars))
fit <- LassoFISTA(betaInit=betalars,y,X,
nopen=c(1),lambda=LassoPen(c=1.1,n=nrow(X),p=ncol(X)),
tol=1e-6,maxIter=1e4,trace=T)
fit
LeastSq(fit$beta,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(fit$beta))
LeastSq(betalars,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(betalars))
LeastSq(fit$beta,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(fit$beta[-1]))
LeastSq(betalars,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(betalars[-1]))
LeastSq(fit$beta,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(fit$beta[-1]))
LeastSq(betalars,y,X) + LassoPen(c=1.1,n=nrow(X),p=ncol(X))*sum(abs(betalars[-1]))
fit <- LassoFISTA(betaInit=rep(0,p),y,X,
nopen=c(1),lambda=LassoPen(c=1.1,n=nrow(X),p=ncol(X)),
tol=1e-6,maxIter=1e4,trace=T)
fity
fit
aa=c(2,3)
class(aa) <- "mo"
aa
class(aa)
? backsolve
? updateR
